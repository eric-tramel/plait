"""Feedback types for the optimization system.

This module provides the FeedbackType enum and Feedback dataclass which
represent evaluation results from loss functions. Feedback objects can
propagate backward through the computation graph to accumulate improvement
suggestions into Parameters.

The API mirrors PyTorch's loss.backward() pattern:
    >>> feedback = await loss_fn(output, target, record=record)
    >>> await feedback.backward()  # Propagates feedback to Parameters

Example:
    >>> from inf_engine.optimization.feedback import Feedback, FeedbackType
    >>>
    >>> # Create feedback from evaluation
    >>> feedback = Feedback(
    ...     content="Response was too verbose",
    ...     score=0.6,
    ...     feedback_type=FeedbackType.LLM_JUDGE,
    ... )
    >>> str(feedback)
    '[0.60] Response was too verbose'
"""

from __future__ import annotations

from dataclasses import dataclass, field
from enum import Enum
from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    from inf_engine.optimization.record import ForwardRecord


class FeedbackType(Enum):
    """Classification of feedback sources.

    Different feedback types may be weighted or processed differently
    during optimization. This enum allows tracking the provenance of
    feedback throughout the backward pass.

    Attributes:
        HUMAN: Feedback provided directly by a human evaluator.
        LLM_JUDGE: Feedback generated by an LLM acting as a judge.
        VERIFIER: Feedback from programmatic verification (code-based checks).
        COMPOSITE: Aggregated feedback from multiple sources.

    Example:
        >>> feedback = Feedback(
        ...     content="Good response",
        ...     feedback_type=FeedbackType.HUMAN,
        ... )
        >>> feedback.feedback_type == FeedbackType.HUMAN
        True
    """

    HUMAN = "human"
    LLM_JUDGE = "llm_judge"
    VERIFIER = "verifier"
    COMPOSITE = "composite"


@dataclass
class Feedback:
    """Feedback on a module output, analogous to a loss tensor in PyTorch.

    Holds the evaluation result and (optionally) a reference to the forward
    pass record for backward propagation. When `backward()` is called,
    feedback propagates through the computation graph to accumulate
    improvement suggestions into Parameters.

    Attributes:
        content: The feedback text describing what was good or bad about
            the output and how it could be improved.
        score: Optional numeric score normalized to 0-1 range, where 1.0
            indicates perfect output and 0.0 indicates complete failure.
        feedback_type: Classification of the feedback source. Defaults
            to HUMAN if not specified.
        metadata: Optional dictionary for storing additional information
            such as raw scores, criteria used, or evaluation context.

    Example:
        >>> # Create feedback with score
        >>> feedback = Feedback(
        ...     content="Response was helpful but too verbose",
        ...     score=0.7,
        ...     feedback_type=FeedbackType.LLM_JUDGE,
        ...     metadata={"criteria": "helpfulness"},
        ... )
        >>> str(feedback)
        '[0.70] Response was helpful but too verbose'
        >>>
        >>> # Create feedback without score
        >>> feedback = Feedback(content="Add more examples")
        >>> str(feedback)
        'Add more examples'
        >>>
        >>> # backward() requires a ForwardRecord
        >>> import asyncio
        >>> asyncio.run(feedback.backward())  # Raises RuntimeError

    Note:
        The `_record` and `_optimizer` fields are internal and should not
        be set directly. They are populated by loss functions when computing
        feedback with `record=record` parameter.
    """

    content: str
    score: float | None = None
    feedback_type: FeedbackType = FeedbackType.HUMAN
    metadata: dict[str, Any] = field(default_factory=dict)

    # Internal: reference to forward pass for backward()
    _record: ForwardRecord | None = field(default=None, repr=False, compare=False)
    _optimizer: Any = field(
        default=None, repr=False, compare=False
    )  # Optimizer type hint avoided for circular import

    async def backward(self, optimizer: Any = None) -> None:
        """Propagate feedback backward through the computation graph.

        This is the primary API for backward passes, mirroring loss.backward()
        in PyTorch. Feedback accumulates into Parameter._feedback_buffer for
        later aggregation by the optimizer.

        Args:
            optimizer: Optional optimizer providing reasoning LLM for
                custom backward implementations. If not provided, uses
                self._optimizer if set.

        Raises:
            RuntimeError: If no ForwardRecord is attached. This happens when
                feedback was computed without passing `record=record` to the
                loss function.

        Example:
            >>> # Correct usage with record
            >>> output, record = await run(module, input, record=True)
            >>> feedback = await loss_fn(output, target, record=record)
            >>> await feedback.backward()  # Works!
            >>>
            >>> # Incorrect usage without record
            >>> feedback = Feedback(content="test")
            >>> await feedback.backward()  # RuntimeError!

        Note:
            The actual backward propagation is implemented in the backward
            module's `_propagate_backward()` function. This method validates
            the record is present and then delegates to that function.
        """
        if self._record is None:
            raise RuntimeError(
                "Cannot call backward() without a ForwardRecord. "
                "Pass record=record when computing feedback."
            )

        # Import here to avoid circular imports
        from inf_engine.optimization.backward import _propagate_backward

        opt = optimizer or self._optimizer
        reasoning_llm = (
            opt.reasoning_llm if opt and hasattr(opt, "reasoning_llm") else None
        )

        await _propagate_backward(
            feedback=self,
            record=self._record,
            reasoning_llm=reasoning_llm,
        )

    @staticmethod
    async def backward_batch(
        feedbacks: list[Feedback],
        optimizer: Any = None,
    ) -> None:
        """Run backward passes for multiple feedbacks concurrently.

        This method enables efficient batch training by running all backward
        passes in parallel. Since feedback accumulation into Parameters is
        append-only (thread-safe), concurrent backward passes are safe.

        This is the batch equivalent of calling `await fb.backward()` on each
        feedback, but runs them concurrently for better performance.

        Args:
            feedbacks: List of Feedback objects to propagate backward.
                Each must have a ForwardRecord attached (from training mode
                or explicit record passing).
            optimizer: Optional optimizer providing reasoning LLM. If provided,
                passed to all backward() calls.

        Raises:
            RuntimeError: If any feedback in the list lacks a ForwardRecord.
                The error is raised before any backward passes are started.

        Example:
            >>> # Training loop with batch backward
            >>> module.train()
            >>> outputs = await module(["in1", "in2", "in3", "in4"])
            >>> feedbacks = await loss_fn.batch(outputs, targets=targets)
            >>> await Feedback.backward_batch(feedbacks, optimizer=optimizer)
            >>> await optimizer.step()

        Example with explicit optimizer:
            >>> feedbacks = [await loss(out, rec=rec) for out, rec in zip(outs, recs)]
            >>> await Feedback.backward_batch(feedbacks, optimizer=my_optimizer)

        Note:
            For very large batches, consider chunking to avoid overwhelming
            the optimizer's reasoning LLM (if present). The concurrent backward
            passes all share the same optimizer's LLM for reasoning calls.
        """
        import asyncio

        # Validate all feedbacks have records before starting
        for i, fb in enumerate(feedbacks):
            if fb._record is None:
                raise RuntimeError(
                    f"Feedback at index {i} has no ForwardRecord. "
                    "Pass record=record when computing feedback."
                )

        # Run all backward passes concurrently
        async def backward_one(fb: Feedback) -> None:
            await fb.backward(optimizer=optimizer)

        await asyncio.gather(*[backward_one(fb) for fb in feedbacks])

    def __str__(self) -> str:
        """Return string representation of the feedback.

        If a score is present, it's prepended to the content in brackets.

        Returns:
            Formatted feedback string.

        Example:
            >>> str(Feedback(content="Good job", score=0.9))
            '[0.90] Good job'
            >>> str(Feedback(content="Needs work"))
            'Needs work'
        """
        if self.score is not None:
            return f"[{self.score:.2f}] {self.content}"
        return self.content
